import streamlit as st
import pandas as pd

from data_preprocessing import preprocess_retail_data
from rfm import calculate_rfm
from clustering import cluster_rfm
from report_generator import generate_llm_report
from google import genai

st.title("Customer Segmentation DSS")
st.write("CSVã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ã ã‘ã§RFMåˆ†æï¼‹ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°ã‚’å®Ÿè¡Œã—ã¾ã™ã€‚")

uploaded_file = st.file_uploader("CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", type="csv")

if uploaded_file:
    # CSVèª­ã¿è¾¼ã¿
    df = pd.read_csv(uploaded_file)
    st.subheader("â‘  ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ãŸãƒ‡ãƒ¼ã‚¿")
    st.dataframe(df.head())

    # å‰å‡¦ç†
    df_clean = preprocess_retail_data(df)
    st.subheader("â‘¡ å‰å‡¦ç†å¾Œã®ãƒ‡ãƒ¼ã‚¿")
    st.dataframe(df_clean.head())

    # RFMè¨ˆç®—
    rfm = calculate_rfm(df_clean)
    st.subheader("â‘¢ RFMãƒ†ãƒ¼ãƒ–ãƒ«")
    st.dataframe(rfm.head())

    # ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°
    k = st.slider("ã‚¯ãƒ©ã‚¹ã‚¿æ•° (k)", 2, 10, 4)
    rfm_clustered, model = cluster_rfm(rfm, k)

    st.subheader("â‘£ ã‚¯ãƒ©ã‚¹ã‚¿çµæœ")
    st.dataframe(rfm_clustered.head())

    # ã‚¯ãƒ©ã‚¹ã‚¿å¹³å‡
    st.subheader("â‘¤ ã‚¯ãƒ©ã‚¹ã‚¿åˆ¥å¹³å‡")
    cluster_means = rfm_clustered.groupby("Cluster").mean()
    st.dataframe(cluster_means)

    # LLMãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
    st.subheader("â‘¥ è‡ªå‹•ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆï¼ˆLLMï¼‰")

    # APIã‚­ãƒ¼ã®å…¥åŠ›ï¼ˆæœ¬ç•ªã¯st.secretsæ¨å¥¨ï¼‰
    api_key = "AIzaSyDLccPtlWzl56CTV1Cab5vBCHna6_otyLw"

    if api_key:
        if st.button("ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆã™ã‚‹"):
            with st.spinner("ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆä¸­..."):
                try:
                    report_text = generate_llm_report(cluster_means)
                    st.markdown("### ğŸ“„ ç”Ÿæˆã•ã‚ŒãŸãƒ¬ãƒãƒ¼ãƒˆ")
                    st.write(report_text)
                except Exception as e:
                    st.error(f"ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
    else:
        st.info("LLMãƒ¬ãƒãƒ¼ãƒˆã‚’ä½¿ã†ã«ã¯ã€APIã‚­ãƒ¼ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")

    st.success("åˆ†æãŒå®Œäº†ã—ã¾ã—ãŸï¼")
